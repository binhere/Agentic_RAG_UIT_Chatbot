{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T03:12:17.935037Z",
     "iopub.status.busy": "2025-05-29T03:12:17.934752Z",
     "iopub.status.idle": "2025-05-29T03:12:18.064852Z",
     "shell.execute_reply": "2025-05-29T03:12:18.063688Z",
     "shell.execute_reply.started": "2025-05-29T03:12:17.935016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version # Python 3.11.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:05:30.198953Z",
     "iopub.status.busy": "2025-06-01T07:05:30.198498Z",
     "iopub.status.idle": "2025-06-01T07:06:55.354469Z",
     "shell.execute_reply": "2025-06-01T07:06:55.353566Z",
     "shell.execute_reply.started": "2025-06-01T07:05:30.198929Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU transformers sentence-transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:06:55.356403Z",
     "iopub.status.busy": "2025-06-01T07:06:55.356145Z",
     "iopub.status.idle": "2025-06-01T07:06:59.859709Z",
     "shell.execute_reply": "2025-06-01T07:06:59.859033Z",
     "shell.execute_reply.started": "2025-06-01T07:06:55.356379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# faiss-cpu with Python 3.11.11 is still fast\n",
    "# In this case, you do not need to use faiss-gpu\n",
    "# Enable P100 GPU only to accelerate embedding model\n",
    "\n",
    "!pip install -q faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T09:02:34.662122Z",
     "iopub.status.busy": "2025-06-01T09:02:34.661447Z",
     "iopub.status.idle": "2025-06-01T09:02:38.944771Z",
     "shell.execute_reply": "2025-06-01T09:02:38.943862Z",
     "shell.execute_reply.started": "2025-06-01T09:02:34.662076Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.52.4\n",
      "Name: sentence-transformers\n",
      "Version: 4.1.0\n",
      "Name: datasets\n",
      "Version: 3.6.0\n",
      "Name: faiss-cpu\n",
      "Version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name: transformers\n",
    "Version: 4.51.3\n",
    "Name: sentence-transformers\n",
    "Version: 4.1.0\n",
    "Name: datasets\n",
    "Version: 3.6.0\n",
    "Name: faiss-cpu\n",
    "Version: 1.11.0\n",
    "\"\"\"\n",
    "\n",
    "# for verbose info, keep only: !pip ... datasets\n",
    "!pip show transformers sentence-transformers datasets faiss-cpu | grep -E '^Name:|^Version:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:06:59.860765Z",
     "iopub.status.busy": "2025-06-01T07:06:59.860570Z",
     "iopub.status.idle": "2025-06-01T07:07:24.494499Z",
     "shell.execute_reply": "2025-06-01T07:07:24.493692Z",
     "shell.execute_reply.started": "2025-06-01T07:06:59.860743Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 07:07:12.124780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748761632.311391      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748761632.364513      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.cross_encoder import CrossEncoder, CrossEncoderTrainer, CrossEncoderTrainingArguments, losses\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "\n",
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:24.496965Z",
     "iopub.status.busy": "2025-06-01T07:07:24.496417Z",
     "iopub.status.idle": "2025-06-01T07:07:24.780194Z",
     "shell.execute_reply": "2025-06-01T07:07:24.779669Z",
     "shell.execute_reply.started": "2025-06-01T07:07:24.496947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "secret_token = user_secrets.get_secret(\"UIT_21520296_DATASET\")\n",
    "login(token=secret_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:24.781048Z",
     "iopub.status.busy": "2025-06-01T07:07:24.780825Z",
     "iopub.status.idle": "2025-06-01T07:07:24.784741Z",
     "shell.execute_reply": "2025-06-01T07:07:24.784147Z",
     "shell.execute_reply.started": "2025-06-01T07:07:24.781024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess(element):\n",
    "    # Replace newlines, tabs, and redundant spaces with a single space\n",
    "    processed_element = re.sub(r'[\\n\\t\\s]+', ' ', element)\n",
    "    \n",
    "    # Strip leading and trailing spaces\n",
    "    processed_element = processed_element.strip()\n",
    "    \n",
    "    return processed_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:24.785695Z",
     "iopub.status.busy": "2025-06-01T07:07:24.785450Z",
     "iopub.status.idle": "2025-06-01T07:07:25.576575Z",
     "shell.execute_reply": "2025-06-01T07:07:25.575730Z",
     "shell.execute_reply.started": "2025-06-01T07:07:24.785674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_train = '/kaggle/input/uit-r2gqa/data-raw/train.csv'\n",
    "path_valid = '/kaggle/input/uit-r2gqa/data-raw/val.csv'\n",
    "path_test  = '/kaggle/input/uit-r2gqa/data-raw/test.csv'\n",
    "\n",
    "df_train = pd.read_csv(path_train)\n",
    "df_valid = pd.read_csv(path_valid)\n",
    "df_test  = pd.read_csv(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:25.577755Z",
     "iopub.status.busy": "2025-06-01T07:07:25.577486Z",
     "iopub.status.idle": "2025-06-01T07:07:25.621819Z",
     "shell.execute_reply": "2025-06-01T07:07:25.621061Z",
     "shell.execute_reply.started": "2025-06-01T07:07:25.577730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (7806, 8) (294,) (7710,)\n",
      "valid (976, 8) (258,) (971,)\n",
      "test (976, 8) (256,) (976,)\n"
     ]
    }
   ],
   "source": [
    "print('train', df_train.shape, df_train['context'].unique().shape, df_train['question'].unique().shape)\n",
    "print('valid', df_valid.shape, df_valid['context'].unique().shape, df_valid['question'].unique().shape)\n",
    "print('test', df_test.shape, df_test['context'].unique().shape, df_test['question'].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:25.622635Z",
     "iopub.status.busy": "2025-06-01T07:07:25.622451Z",
     "iopub.status.idle": "2025-06-01T07:07:25.629037Z",
     "shell.execute_reply": "2025-06-01T07:07:25.628359Z",
     "shell.execute_reply.started": "2025-06-01T07:07:25.622621Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'context', 'article', 'document', 'question',\n",
       "       'extractive answer', 'abstractive answer', 'yes/no'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:25.630060Z",
     "iopub.status.busy": "2025-06-01T07:07:25.629877Z",
     "iopub.status.idle": "2025-06-01T07:07:25.641779Z",
     "shell.execute_reply": "2025-06-01T07:07:25.641141Z",
     "shell.execute_reply.started": "2025-06-01T07:07:25.630045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['index', 'article', 'document', 'extractive answer', 'abstractive answer', 'yes/no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:25.644367Z",
     "iopub.status.busy": "2025-06-01T07:07:25.643769Z",
     "iopub.status.idle": "2025-06-01T07:07:26.709718Z",
     "shell.execute_reply": "2025-06-01T07:07:26.709158Z",
     "shell.execute_reply.started": "2025-06-01T07:07:25.644350Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7806, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Điều 9. Tuyển bổ sung và loại ra khỏi chương t...</td>\n",
       "      <td>Sinh viên dự bị không trở thành sinh viên chín...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Điều 4. Kiểm tra xếp lớp đầu khóa cho sinh viê...</td>\n",
       "      <td>Các mức điểm xếp lớp tiếng Anh được Hiệu trưởn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Điều 5. Chương trình đào tạo CT CLC được xây d...</td>\n",
       "      <td>Trình độ tiếng Nhật đạt N mấy mới thì sinh viê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Điều 25. Cách tính điểm trung bình 1. ĐTBHK, Đ...</td>\n",
       "      <td>Cách tính điểm giữa điểm trung bình học kỳ, đi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Điều 19. Tổ chức phúc khảo và giải quyết khiếu...</td>\n",
       "      <td>Hoạt động nào sẽ diễn ra khi SV có khiếu nại v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Điều 9. Tuyển bổ sung và loại ra khỏi chương t...   \n",
       "1  Điều 4. Kiểm tra xếp lớp đầu khóa cho sinh viê...   \n",
       "2  Điều 5. Chương trình đào tạo CT CLC được xây d...   \n",
       "3  Điều 25. Cách tính điểm trung bình 1. ĐTBHK, Đ...   \n",
       "4  Điều 19. Tổ chức phúc khảo và giải quyết khiếu...   \n",
       "\n",
       "                                            question  \n",
       "0  Sinh viên dự bị không trở thành sinh viên chín...  \n",
       "1  Các mức điểm xếp lớp tiếng Anh được Hiệu trưởn...  \n",
       "2  Trình độ tiếng Nhật đạt N mấy mới thì sinh viê...  \n",
       "3  Cách tính điểm giữa điểm trung bình học kỳ, đi...  \n",
       "4  Hoạt động nào sẽ diễn ra khi SV có khiếu nại v...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop(columns=columns_to_drop, inplace=True)\n",
    "df_train = df_train.map(func=preprocess)\n",
    "\n",
    "print(df_train.shape)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:26.710595Z",
     "iopub.status.busy": "2025-06-01T07:07:26.710387Z",
     "iopub.status.idle": "2025-06-01T07:07:26.854198Z",
     "shell.execute_reply": "2025-06-01T07:07:26.853649Z",
     "shell.execute_reply.started": "2025-06-01T07:07:26.710579Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(976, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Điều 16. Xử lý học vụ Xử lý học vụ nhằm giúp c...</td>\n",
       "      <td>Sinh viên chưa hết thời gian tối đa hoàn thành...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Điều 32. Chấm thực tập, khóa luận tốt nghiệp 1...</td>\n",
       "      <td>Điểm của khoá luận tính theo thang điểm mấy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Điều 11. Đào tạo ngoại ngữ - Vào đầu khóa học,...</td>\n",
       "      <td>Vào đầu mỗi khóa học sinh viên CT CLC cần phải...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Điều 9. Văn bằng, chứng chỉ/chứng nhận được sử...</td>\n",
       "      <td>Tại sao sinh viên cần nộp chứng chỉ cho Trường?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Điều 1. Phạm vi điều chỉnh và đối tượng áp dụn...</td>\n",
       "      <td>Văn bằng giáo dục đại học, sau đại học và các ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Điều 16. Xử lý học vụ Xử lý học vụ nhằm giúp c...   \n",
       "1  Điều 32. Chấm thực tập, khóa luận tốt nghiệp 1...   \n",
       "2  Điều 11. Đào tạo ngoại ngữ - Vào đầu khóa học,...   \n",
       "3  Điều 9. Văn bằng, chứng chỉ/chứng nhận được sử...   \n",
       "4  Điều 1. Phạm vi điều chỉnh và đối tượng áp dụn...   \n",
       "\n",
       "                                            question  \n",
       "0  Sinh viên chưa hết thời gian tối đa hoàn thành...  \n",
       "1       Điểm của khoá luận tính theo thang điểm mấy?  \n",
       "2  Vào đầu mỗi khóa học sinh viên CT CLC cần phải...  \n",
       "3    Tại sao sinh viên cần nộp chứng chỉ cho Trường?  \n",
       "4  Văn bằng giáo dục đại học, sau đại học và các ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.drop(columns=columns_to_drop, inplace=True)\n",
    "df_valid = df_valid.map(func=preprocess)\n",
    "\n",
    "print(df_valid.shape)\n",
    "df_valid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:26.855231Z",
     "iopub.status.busy": "2025-06-01T07:07:26.854963Z",
     "iopub.status.idle": "2025-06-01T07:07:27.001758Z",
     "shell.execute_reply": "2025-06-01T07:07:27.001249Z",
     "shell.execute_reply.started": "2025-06-01T07:07:26.855209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(976, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Điều 8. Xây dựng, thẩm định học liệu điện tử 1...</td>\n",
       "      <td>Học liệu điện tử sau khi được thông qua bởi ĐV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Điều 20. Hồ sơ, trình tự, thủ tục chỉnh sửa nộ...</td>\n",
       "      <td>Có thể nộp bản sao giấy khai sinh cho hồ sơ đề...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Điều 23. Điểm Miễn 1. Điểm BL - Sinh viên đã t...</td>\n",
       "      <td>Quy định về điểm M trong trường hợp sinh viên ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Điều 4. Xét duyệt đề tài KLTN Khoa chịu trách ...</td>\n",
       "      <td>Yêu cầu đối với học vị của CBHD hướng dẫn KLTN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Điều 11. Quy trình chuẩn bị cho kỳ thi 1. Đầu ...</td>\n",
       "      <td>Công việc phân công cán bộ coi thi có nội dung...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Điều 8. Xây dựng, thẩm định học liệu điện tử 1...   \n",
       "1  Điều 20. Hồ sơ, trình tự, thủ tục chỉnh sửa nộ...   \n",
       "2  Điều 23. Điểm Miễn 1. Điểm BL - Sinh viên đã t...   \n",
       "3  Điều 4. Xét duyệt đề tài KLTN Khoa chịu trách ...   \n",
       "4  Điều 11. Quy trình chuẩn bị cho kỳ thi 1. Đầu ...   \n",
       "\n",
       "                                            question  \n",
       "0  Học liệu điện tử sau khi được thông qua bởi ĐV...  \n",
       "1  Có thể nộp bản sao giấy khai sinh cho hồ sơ đề...  \n",
       "2  Quy định về điểm M trong trường hợp sinh viên ...  \n",
       "3  Yêu cầu đối với học vị của CBHD hướng dẫn KLTN...  \n",
       "4  Công việc phân công cán bộ coi thi có nội dung...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.drop(columns=columns_to_drop, inplace=True)\n",
    "df_test = df_test.map(func=preprocess)\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:27.002531Z",
     "iopub.status.busy": "2025-06-01T07:07:27.002359Z",
     "iopub.status.idle": "2025-06-01T07:07:27.234382Z",
     "shell.execute_reply": "2025-06-01T07:07:27.233766Z",
     "shell.execute_reply.started": "2025-06-01T07:07:27.002516Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question'],\n",
       "    num_rows: 7806\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_train = Dataset.from_pandas(df_train)\n",
    "hf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:27.235582Z",
     "iopub.status.busy": "2025-06-01T07:07:27.235319Z",
     "iopub.status.idle": "2025-06-01T07:07:27.266066Z",
     "shell.execute_reply": "2025-06-01T07:07:27.265561Z",
     "shell.execute_reply.started": "2025-06-01T07:07:27.235559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question'],\n",
       "    num_rows: 976\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_valid = Dataset.from_pandas(df_valid)\n",
    "hf_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:27.266951Z",
     "iopub.status.busy": "2025-06-01T07:07:27.266719Z",
     "iopub.status.idle": "2025-06-01T07:07:27.289667Z",
     "shell.execute_reply": "2025-06-01T07:07:27.289059Z",
     "shell.execute_reply.started": "2025-06-01T07:07:27.266934Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question'],\n",
       "    num_rows: 976\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_test = Dataset.from_pandas(df_test)\n",
    "hf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to use [**mine_hard_negatives**](https://sbert.net/docs/package_reference/util.html#sentence_transformers.util.mine_hard_negatives):\n",
    "\n",
    "`output_format` can be set to `labeled-pair` which can be used with [BinaryCrossEntropyLoss](https://sbert.net/docs/package_reference/cross_encoder/losses.html#sentence_transformers.cross_encoder.losses.BinaryCrossEntropyLoss). <br>\n",
    "This combination is easier to implement than combination of `output_format=\"triplet\"` and [MultipleNegativesRankingLoss](https://sbert.net/docs/package_reference/cross_encoder/losses.html#sentence_transformers.cross_encoder.losses.MultipleNegativesRankingLoss)  \n",
    "\n",
    "*(read section Recommendations in document of both losses for more info)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:27.290734Z",
     "iopub.status.busy": "2025-06-01T07:07:27.290508Z",
     "iopub.status.idle": "2025-06-01T07:07:58.827199Z",
     "shell.execute_reply": "2025-06-01T07:07:58.826381Z",
     "shell.execute_reply.started": "2025-06-01T07:07:27.290718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49a6565e12946e5895fbfb908ed5139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b97c77c2e384b0da5ba1c45b9824004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/208 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545307598fd34a65ae481d2d196fa96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47101448e1f4f49a9771e6b2fae61a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/56.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c0da8f9025414590533332ccfea174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e6584756cf4bd8b62669e1ee73585c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7c2e103e734a618270b10bb22573a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3005b5824d3b4d9e82f98e50f3061150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13fe197cd7648e3b33b18ae136ad474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b961f6c7c74568a01659f2ea65c340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/305 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers.util import mine_hard_negatives\n",
    "\n",
    "# **RE-USE** bi-encoder 'KhoaUIT/Halong-UIT-R2GQA' which is already trained on the same dataset\n",
    "# Mine hard negatives using a very efficient embedding model\n",
    "embedding_model = SentenceTransformer(\"KhoaUIT/Halong-UIT-R2GQA\", device=\"cuda\")\n",
    "\n",
    "\n",
    "def make_hard_dataset(input_dataset, output_format=\"triplet\", num_negatives=3):    \n",
    "    # Params for input dataset:\n",
    "    # anchor_column_name   (str, optional) – The column name in dataset that contains the anchor/query. Defaults to None, in which case the first column in dataset will be used.\n",
    "    # positive_column_name (str, optional) – The column name in dataset that contains the positive candidates. Defaults to None, in which case the second column in dataset will be used.\n",
    "    \n",
    "    dataset_hard = mine_hard_negatives(\n",
    "        input_dataset,\n",
    "        embedding_model,\n",
    "        anchor_column_name=\"question\",\n",
    "        positive_column_name=\"context\",\n",
    "        num_negatives=num_negatives,   # How many negatives per question-answer pair\n",
    "        sampling_strategy=\"top\",       # Sample the top negatives from the range\n",
    "        range_min=8,                   # Skip the x most similar samples\n",
    "        range_max=200,                 # Consider only the x most similar samples\n",
    "        max_score=0.8,                 # Only consider samples with a similarity score of at most x\n",
    "        absolute_margin=0.1,           # Anchor-negative similarity is at least x lower than anchor-positive similarity\n",
    "        relative_margin=0.1,           # Anchor-negative similarity is at most 1-x times the anchor-positive similarity, e.g. 90%\n",
    "        batch_size=512,                # Use a batch size for the embedding model\n",
    "        output_format=output_format,   # ”triplet”: (anchor, positive, negative) triplets, i.e. 3 columns. Useful for e.g. CachedMultipleNegativesRankingLoss\n",
    "        use_faiss=True,                # Using FAISS is recommended to keep memory usage low (pip install faiss-gpu or pip install faiss-cpu)\n",
    "    )\n",
    "\n",
    "    return dataset_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:07:58.828774Z",
     "iopub.status.busy": "2025-06-01T07:07:58.828060Z",
     "iopub.status.idle": "2025-06-01T07:08:14.033577Z",
     "shell.execute_reply": "2025-06-01T07:08:14.032981Z",
     "shell.execute_reply.started": "2025-06-01T07:07:58.828748Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7701 unique queries out of 7806 total queries.\n",
      "Found an average of 1.014 positives per query.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1c7bfcd06d405abc8823cee656f567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3edeee0a87d4fd78f585d066a964961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying FAISS index: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count           7,806          7,806               \n",
      "Mean           0.8394         0.5545         0.2849\n",
      "Median         0.8444         0.5532         0.2832\n",
      "Std            0.0540         0.0360         0.0577\n",
      "Min            0.5740         0.4305         0.1155\n",
      "25%            0.8042         0.5289         0.2432\n",
      "50%            0.8444         0.5532         0.2832\n",
      "75%            0.8793         0.5785         0.3260\n",
      "Max            0.9639         0.7187         0.4754\n",
      "Skipped 7,282 potential negatives (0.47%) due to the absolute_margin of 0.1.\n",
      "Skipped 112 potential negatives (0.01%) due to the max_score of 0.8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['question', 'context', 'negative'],\n",
       "     num_rows: 7806\n",
       " }),\n",
       " {'question': 'Yêu cầu của giáo trình được sử dụng cho việc giảng dạy là gì?',\n",
       "  'context': 'Điều 5. Giáo trình cho mỗi học phần 5.1. Mỗi học phần dùng một giáo trình chính. Trong từng giai đoạn, giáo trình cho học phần có thể thay đổi do Hiệu trưởng ra quyết định. 5.2. Ngoài một giáo trình chính, mỗi học phần được trường tổ chức biên soạn tối đa hai sách chuyên khảo, ba tài liệu tham khảo, một tài liệu hướng dẫn. 5.3. Các giáo trình sử dụng trong giảng dạy phải được ghi rõ trong đề cương học phần đã được Hiệu trưởng phê duyệt.',\n",
       "  'negative': 'Điều 13. Kinh phí giáo trình ĐHQG hỗ trợ cho xuất bản giáo trình 13.1. Đối với giáo trình xuất bản Để thúc đẩy cho công tác giáo trình phát triển nhanh, đáp ứng kịp cho nhu cầu đào tạo, ĐHQG chi hỗ trợ một phần kinh phí. Cụ thể là: a) Hỗ trợ 50% cho phí in đối với giáo trình có số lượng xuất bản đến 500 quyển. Cụ thể, mức hỗ trợ kinh phí in 1 tựa giáo trình được tính như sau: = (đơn giá in 1 trang × số trang × số lượng giáo trình xuất bản) × 50% b) Hỗ trợ 100% phí quản lý và phí biên tập của NXB ĐHQG. 13.2. Đối với giáo trình tái bản Giáo trình tái bản được hỗ trợ kinh phí theo mức ghi ở mục a, b khoản 1 Điều này.'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hard = make_hard_dataset(hf_train, num_negatives=1)\n",
    "train_hard, train_hard[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:08:14.034578Z",
     "iopub.status.busy": "2025-06-01T07:08:14.034285Z",
     "iopub.status.idle": "2025-06-01T07:08:19.893192Z",
     "shell.execute_reply": "2025-06-01T07:08:19.892656Z",
     "shell.execute_reply.started": "2025-06-01T07:08:14.034553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 971 unique queries out of 976 total queries.\n",
      "Found an average of 1.005 positives per query.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c344c830feea4012bdb94e791433ee85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919ee40762524b8d896ef457a9d49ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying FAISS index: 100%|██████████| 1/1 [00:00<00:00, 52.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count             976            974               \n",
      "Mean           0.8118         0.5376         0.2751\n",
      "Median         0.8327         0.5386         0.2795\n",
      "Std            0.0933         0.0422         0.0735\n",
      "Min            0.3503         0.2731         0.1053\n",
      "25%            0.7721         0.5167         0.2257\n",
      "50%            0.8327         0.5386         0.2800\n",
      "75%            0.8755         0.5631         0.3292\n",
      "Max            0.9637         0.6621         0.4420\n",
      "Skipped 3,591 potential negatives (1.84%) due to the absolute_margin of 0.1.\n",
      "Skipped 13 potential negatives (0.01%) due to the max_score of 0.8.\n",
      "Could not find enough negatives for 2 samples (0.20%). Consider adjusting the range_max, range_min, absolute_margin, relative_margin and max_score parameters if you'd like to find more valid negatives.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['question', 'context', 'negative'],\n",
       "     num_rows: 974\n",
       " }),\n",
       " {'question': 'Trường hợp một SV được CBCT cho xem bài của SV khác trong giờ thi được giải quyết như thế nào?',\n",
       "  'context': 'Điều 22. Xử lý cán bộ vi phạm quy định Trong thời gian thi, nếu các cán bộ thanh tra thi phát hiện thấy các trường hợp vi phạm thì lập biên bản tại chỗ và đề nghị Hiệu trưởng xử lý. Người tham gia công tác thi có hành vi vi phạm quy định (bị phát hiện trong khi làm nhiệm vụ hoặc sau kỳ thi), nếu có đủ chứng cứ, tùy theo mức độ, sẽ bị xử lý theo các hình thức sau đây. 1. Khiển trách đối với những người phạm lỗi nhẹ trong khi thi hành nhiệm vụ. 2. Cảnh cáo đối với những người vi phạm một trong các lỗi sau đây: a. CBCT bỏ coi thi mà không thông báo cho đơn vị tổ chức môn thi từ 2 lần trở lên trong một đợt thi. b. CBCT để cho SV tự do trao đổi khi làm bài, sử dụng tài liệu bị cấm sử dụng hoặc sử dụng các phương tiện thông tin liên lạc tại phòng thi. c. Cán bộ chấm thi chấm điểm hoặc cộng điểm bài thi có nhiều sai sót (trên 5% tổng số bài thi). d. Cán bộ chấm thi nộp điểm trễ so với thời hạn quy định. 3. Tùy theo mức độ vi phạm có thể bị hạ bậc lương, hạ ngạch, cách chức hoặc chuyển đi làm công tác khác đối với những người vi phạm một trong các lỗi sau đây: a. Trực tiếp giải bài rồi hướng dẫn cho SV lúc đang thi. b. Lấy bài thi của SV làm được giao cho SV khác. 4. Buộc thôi việc hoặc bị xử lý theo pháp luật đối với người có một trong các hành vi sai phạm sau đây: a. Làm lộ đề thi, mua, bán đề thi. b. Đưa đề thi ra ngoài khu vực thi hoặc đưa bài giải từ ngoài vào phòng thi trong lúc đang thi. c. Cố tình làm sai lệch điểm trên bài thi hoặc trong bảng điểm. d. Đánh tráo bài thi của SV. 5. Cán bộ làm mất bài thi của SV khi thu bài thi, vận chuyển, bảo quản, chấm thi hoặc có những sai phạm khác trong công tác tổ chức thi, tùy theo tính chất, mức độ vi phạm sẽ bị xử lý vi phạm theo một trong các hình thức quy định tại Điều này. 6. Những cán bộ, SV tuy không tham gia công tác thi nhưng nếu có các hành động tiêu cực như: thi hộ, tổ chức lấy đề thi ra và đưa bài giải vào cho SV, gây rối làm mất trất tự tại khu vực thi sẽ bị buộc thôi việc (nếu là cán bộ) hoặc buộc thôi học (nếu là học sinh, SV).',\n",
       "  'negative': 'Điều 10. Giảng dạy các môn CTTN CTTN phải được thực hiện trên quan điểm lấy người học làm trung tâm. Người học phải được tạo điều kiện để thể hiện vai trò chủ động trong tiến trình học tập. Người học phải đóng vai trò chủ động trong hoạt động học tập, thay vì thụ động tiếp nhận kiến thức. Sinh viên CTTN sẽ học cùng với sinh viên các lớp chương trình chuẩn trong các môn được đào tạo chung, các môn học cốt lõi dành riêng cho sinh viên CTTN được tổ chức lớp học riêng. Khoa quản lý chuyên môn có trách nhiệm chọn các cán bộ có kinh nghiệm để phụ trách giảng dạy. Các môn học tài năng và KLTN phải do CBGD có học vị tiến sĩ hoặc giảng viên chính, hoặc thạc sĩ tốt nghiệp ở các trường Đại học thuộc các nước tiên tiến, đúng ngành hoặc thuộc ngành gần đảm nhiệm. Trong tuần đầu tiên của học kỳ, CBGD phải thông báo công khai cho sinh viên về đề cương giảng dạy môn học; trong đó đặc biệt chú ý các thông tin, các phần học bổ sung tăng cường; số cột điểm và tỷ lệ tính của từng cột điểm vào điểm tổng kết môn học. CBGD phải cung cấp đầy đủ đề cương môn học, tài liệu và công bố nội dung bài giảng trước cho sinh viên trên trang web môn học. Đầu mỗi học kỳ, đại diện đơn vị quản lý chương trình và các CVHT phải gặp gỡ đại diện sinh viên (ít nhất 3 SV/lớp – do lớp bầu chọn) tất cả các lớp CTTN để trao đổi và nhận phản hồi về tình hình giảng dạy và sinh hoạt. Cuối học kỳ, BĐH phối hợp với phòng Thanh tra - Pháp chế - Đảm bảo chất lượng tổ chức lấy ý kiến sinh viên (dùng phiếu thăm dò, qua trang web,…) về giảng dạy môn học và tổ chức cho CBGD rút kinh nghiệm về các góp ý của sinh viên. Ngoài nội dung bắt buộc theo đề cương, các môn CTTN có thể có thêm các nội dung tăng cường và một số lượng hạn chế các buổi \"seminar ngoại khóa\". Lịch dạy và lịch dạy bổ sung tăng cường, dạy bù được báo cáo và kiểm tra theo quy trình chung như lớp đại học chính quy đại trà.'})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_hard = make_hard_dataset(hf_valid, num_negatives=1)\n",
    "valid_hard, valid_hard[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:08:19.894075Z",
     "iopub.status.busy": "2025-06-01T07:08:19.893833Z",
     "iopub.status.idle": "2025-06-01T07:08:25.837074Z",
     "shell.execute_reply": "2025-06-01T07:08:25.836345Z",
     "shell.execute_reply.started": "2025-06-01T07:08:19.894051Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b976c94310d745a0b1f78411ce01f39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd41297958d48bbaea468489fe113d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying FAISS index: 100%|██████████| 1/1 [00:00<00:00, 53.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric       Positive       Negative     Difference\n",
      "Count             976            976               \n",
      "Mean           0.8079         0.5385         0.2695\n",
      "Median         0.8304         0.5399         0.2752\n",
      "Std            0.0926         0.0462         0.0697\n",
      "Min            0.3748         0.2659         0.1061\n",
      "25%            0.7693         0.5150         0.2224\n",
      "50%            0.8305         0.5400         0.2753\n",
      "75%            0.8729         0.5675         0.3208\n",
      "Max            0.9553         0.6447         0.4433\n",
      "Skipped 3,811 potential negatives (1.94%) due to the absolute_margin of 0.1.\n",
      "Skipped 6 potential negatives (0.00%) due to the max_score of 0.8.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['question', 'context', 'negative'],\n",
       "     num_rows: 976\n",
       " }),\n",
       " {'question': 'Trưởng Ban điều hành CTGT cần phê duyệt những cái gì?',\n",
       "  'context': 'Điều 7. Quy trình tổ chức biên soạn giáo trình – Chủ biên xây dựng dự thảo đề cương chi tiết giáo trình và báo cáo trước Hội đồng khoa học và Đào tạo cấp Khoa. – Khoa thực hiện thủ tục đăng ký thực hiện giáo trình với Ban điều hành CTGT vào đầu tháng 11 hàng năm. – Trưởng Ban điều hành CTGT duyệt danh sách giáo trình đăng ký và ký hợp đồng biên soạn giáo trình với chủ biên theo đề cương đã được Khoa duyệt. – Chủ biên tạm ứng kinh phí tại Phòng Kế hoạch Tài chính và chi tạm ứng cho các cá nhân tham gia biên soạn. – Chủ biên tổ chức biên soạn bản thảo. – Trưởng Ban điều hành CTGT trường ra quyết định mời cán bộ phản biện. Chức danh khoa học, học vị của người phản biện không được thấp hơn chức danh khoa học, học vị quy định đối với người biên soạn giáo trình. – Sau khi hoàn chỉnh bản thảo, chủ biên đóng thành quyển, gửi cho phản biện và đề nghị Trưởng Ban điều hành CTGT trường thành lập Hội đồng thẩm định. – Trưởng Ban Điều hành CTGT ra quyết định thành lập Hội đồng thẩm định. – Chủ tịch Hội đồng thẩm định tổ chức họp để thẩm định giáo trình, Ủy viên thư ký Hội đồng ghi biên bản cuộc họp. – Nhóm biên soạn sửa chữa, điều chỉnh bản thảo và nộp cho thư ký Ban điều hành CTGT trường. – Thư ký Ban điều hành CTGT trường có trách nhiệm trình Trưởng Ban điều hành CTGT phê duyệt: tên giáo trình, loại giáo trình, công dụng của giáo trình, số lượng xuất bản, chủ biên, những người tham gia biên soạn, … và chuyển bản thảo giáo trình đến Nhà Xuất bản ĐHQG làm thủ tục xuất bản. – Sau khi giáo trình được in, Ban điều hành CTGT trường phân phối giáo trình theo Điều 10.',\n",
       "  'negative': 'Điều 18. Hoạt động kiểm tra, giám sát – Ban điều hành CTGT trường ĐHCNTT có trách nhiệm kiểm tra, giám sát các khâu trong công tác quản lý giáo trình tại trường theo đúng Quy định về CTGT của trường ĐHCNTT. – Các Khoa, CBGD tham gia công tác biên soạn giáo trình phục vụ đào tạo tại trường ĐHCNTT có trách nhiệm báo cáo tiến độ thực hiện việc biên soạn theo yêu cầu của Ban điều hành CTGT trường.'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hard = make_hard_dataset(hf_test, num_negatives=1)\n",
    "test_hard, test_hard[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:08:25.838517Z",
     "iopub.status.busy": "2025-06-01T07:08:25.838028Z",
     "iopub.status.idle": "2025-06-01T07:08:26.285784Z",
     "shell.execute_reply": "2025-06-01T07:08:26.285247Z",
     "shell.execute_reply.started": "2025-06-01T07:08:25.838497Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# recheck hard dataset to make sure that 'context' columns and 'negative' column are not identical\n",
    "\n",
    "def is_qualified(dataset):\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        if sample['context'] == sample['negative']:\n",
    "            return False\n",
    "    return True\n",
    "        \n",
    "print(is_qualified(train_hard))\n",
    "print(is_qualified(valid_hard))\n",
    "print(is_qualified(test_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T08:04:28.290273Z",
     "iopub.status.busy": "2025-06-01T08:04:28.289760Z",
     "iopub.status.idle": "2025-06-01T08:04:31.980909Z",
     "shell.execute_reply": "2025-06-01T08:04:31.980353Z",
     "shell.execute_reply.started": "2025-06-01T08:04:28.290248Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at KhoaUIT/Halong-UIT-R2GQA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize CrossEncoder model\n",
    "\n",
    "model = CrossEncoder(\"KhoaUIT/Halong-UIT-R2GQA\", num_labels=1, max_length=512, device='cuda') # num_labels=1 is for rerankers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:08:28.329271Z",
     "iopub.status.busy": "2025-06-01T07:08:28.328938Z",
     "iopub.status.idle": "2025-06-01T07:08:28.332536Z",
     "shell.execute_reply": "2025-06-01T07:08:28.331896Z",
     "shell.execute_reply.started": "2025-06-01T07:08:28.329250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model_phobert = CrossEncoder(\"KhoaUIT/Phobert-UIT-R2GQA\", num_labels=1, max_length=256, device='cuda')\n",
    "\n",
    "# print(f\"Halong tokenizer is_fast: {model.tokenizer.is_fast}\") # True\n",
    "# print(f\"Phobert tokenizer is_fast: {model_phobert.tokenizer.is_fast}\") # False\n",
    "\n",
    "# for some reason, using \"KhoaUIT/Phobert-UIT-R2GQA\" as Cross-Encoder to evaluate dataset causing following warning:\n",
    "# Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.how ever\n",
    "# However, both models still work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:08:28.334142Z",
     "iopub.status.busy": "2025-06-01T07:08:28.333437Z",
     "iopub.status.idle": "2025-06-01T07:08:28.351666Z",
     "shell.execute_reply": "2025-06-01T07:08:28.351142Z",
     "shell.execute_reply.started": "2025-06-01T07:08:28.334116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CrossEncoderRerankingEvaluator\n",
    "\n",
    "def get_evaluator(dataset=None, name=None, k=10):\n",
    "    assert dataset != None, \"you forgot to pass your dataset\"\n",
    "    assert name != None, \"you should set name of evaluator\"\n",
    "\n",
    "    samples = [\n",
    "        {\n",
    "            \"query\": sample[\"question\"],\n",
    "            \"positive\": [sample[\"context\"]],   # ground truth relevant doc\n",
    "            \"negative\": [sample[\"negative\"]],  # hard negative\n",
    "        }\n",
    "        for sample in dataset  \n",
    "    ]\n",
    "\n",
    "    # Initialize the evaluator\n",
    "    reranking_evaluator = CrossEncoderRerankingEvaluator(\n",
    "        samples=samples,\n",
    "        name=name,\n",
    "        at_k=k,\n",
    "        show_progress_bar=True,\n",
    "        always_rerank_positives=True,  # since we’re using negatives explicitly\n",
    "    )\n",
    "\n",
    "    return reranking_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T08:58:51.136342Z",
     "iopub.status.busy": "2025-05-27T08:58:51.135780Z",
     "iopub.status.idle": "2025-05-27T08:59:23.581433Z",
     "shell.execute_reply": "2025-05-27T08:59:23.580693Z",
     "shell.execute_reply.started": "2025-05-27T08:58:51.136319Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid_map': 0.7453798767967146, 'valid_mrr@10': 0.7453798767967146, 'valid_ndcg@10': 0.8120545767673951}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "valid_evaluator = get_evaluator(valid_hard, \"valid\")\n",
    "results = valid_evaluator(model)\n",
    "\n",
    "# KhoaUIT/Phobert-UIT-R2GQA: {'valid_map': 0.7582135523613963, 'valid_mrr@10': 0.7582135523613963, 'valid_ndcg@10': 0.8215276323738772}\n",
    "# KhoaUIT/Halong-UIT-R2GQA:  {'valid_map': 0.75564681724846,   'valid_mrr@10': 0.75564681724846,   'valid_ndcg@10': 0.8196330212525806}\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:24:33.594415Z",
     "iopub.status.busy": "2025-05-29T07:24:33.594119Z",
     "iopub.status.idle": "2025-05-29T07:24:33.598554Z",
     "shell.execute_reply": "2025-05-29T07:24:33.597606Z",
     "shell.execute_reply.started": "2025-05-29T07:24:33.594394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage:**\n",
    "\n",
    "[**BatchSamplers.NO_DUPLICATES**](https://sbert.net/docs/package_reference/sentence_transformer/sampler.html#sentence_transformers.sampler.NoDuplicatesBatchSampler): This sampler creates batches such that each batch contains samples where the values are unique, even across columns. This is useful when losses consider other samples in a batch to be in-batch negatives, and you want to ensure that the negatives are not duplicates of the anchor/positive sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T08:05:45.521072Z",
     "iopub.status.busy": "2025-06-01T08:05:45.520549Z",
     "iopub.status.idle": "2025-06-01T08:05:47.674860Z",
     "shell.execute_reply": "2025-06-01T08:05:47.674303Z",
     "shell.execute_reply.started": "2025-06-01T08:05:45.521048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "args = CrossEncoderTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=\"reranker-Halong\",\n",
    "    \n",
    "    # Optional training parameters:\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    dataloader_drop_last=True,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,   \n",
    "    bf16=False,\n",
    "    batch_sampler= BatchSamplers.NO_DUPLICATES, # without setting dataloader_drop_last=True, BatchSamplers.NO_DUPLICATES will raise error if there are any duplicates in a batch, it will remove them and lead to invalid batch. \n",
    "                                                # using default BatchSamplers.BATCH_SAMPLER works well but MultipleNegativesRankingLoss remmcomends to use BatchSamplers.NO_DUPLICATES which is better option\n",
    "    \n",
    "    # Optional tracking/debugging parameters:\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss', # we aim to minimize train loss, so using val loss to monitor is easily comparable\n",
    "    greater_is_better=False,\n",
    "    save_total_limit=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    save_strategy=\"steps\", # option \"best\" does not work, 'best_model_checkpoint' in trainer state is None => use \"epoch\" instead if needed\n",
    "    save_steps=250,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=250,\n",
    "    logging_dir=\"logs\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# [IMPORTANT]:\n",
    "# (1): num_negatives in MultipleNegativesRankingLoss (which differs from the one of Sentence Transformer) must match num_negatives in hard dataset obtained by fn mine_hard_negatives()\n",
    "# (2): MultipleNegativesRankingLoss expects to work with option BatchSamplers.NO_DUPLICATES in CrossEncoderTrainingArguments\n",
    "loss = losses.MultipleNegativesRankingLoss(model, num_negatives=1) \n",
    "\n",
    "early_stop = EarlyStoppingCallback(2)\n",
    "\n",
    "trainer = CrossEncoderTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_hard,\n",
    "    eval_dataset=valid_hard,\n",
    "    loss=loss,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T08:05:47.675997Z",
     "iopub.status.busy": "2025-06-01T08:05:47.675772Z",
     "iopub.status.idle": "2025-06-01T08:05:47.684697Z",
     "shell.execute_reply": "2025-06-01T08:05:47.684150Z",
     "shell.execute_reply.started": "2025-06-01T08:05:47.675973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(975, 121, ('eval_step should be', 243.75))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = trainer.get_train_dataloader()\n",
    "valid_loader = trainer.get_eval_dataloader()\n",
    "\n",
    "len(train_loader), len(valid_loader), ('eval_step should be', 0.25*len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:33:58.913174Z",
     "iopub.status.busy": "2025-06-01T07:33:58.912588Z",
     "iopub.status.idle": "2025-06-01T07:33:58.918706Z",
     "shell.execute_reply": "2025-06-01T07:33:58.918073Z",
     "shell.execute_reply.started": "2025-06-01T07:33:58.913150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# observe each batch after CrossEncoderTrainingArguments configuration\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def debug_batches(dataloader):\n",
    "    print('total batches:', len(dataloader))\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        print(f\"\\n📦 Batch {i+1}\")\n",
    "        all_sample_values = []\n",
    "\n",
    "        # Go through each sample in a single batch\n",
    "        batch_size = len(batch['question'])\n",
    "        for j in range(batch_size):\n",
    "            sample_values = {\n",
    "                str(batch[key][j]) for key in batch\n",
    "            }\n",
    "            all_sample_values.extend(sample_values)\n",
    "\n",
    "        # Count and show duplicates\n",
    "        counter = Counter(all_sample_values)\n",
    "        num_duplicates = sum(1 for count in counter.values() if count > 1)\n",
    "\n",
    "        for key, tensor in batch.items():\n",
    "            print(f\"   🔹 {key}: shape {len(tensor)}\")\n",
    "        print(f\"   🔍 Duplicated values in this batch: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T07:35:03.707600Z",
     "iopub.status.busy": "2025-06-01T07:35:03.707000Z",
     "iopub.status.idle": "2025-06-01T07:35:03.711137Z",
     "shell.execute_reply": "2025-06-01T07:35:03.710160Z",
     "shell.execute_reply.started": "2025-06-01T07:35:03.707574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# debug_batches(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T08:06:01.685050Z",
     "iopub.status.busy": "2025-06-01T08:06:01.684587Z",
     "iopub.status.idle": "2025-06-01T08:59:06.620799Z",
     "shell.execute_reply": "2025-06-01T08:59:06.619999Z",
     "shell.execute_reply.started": "2025-06-01T08:06:01.685026Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ model is traing now -----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2250' max='2925' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2925 52:59 < 15:54, 0.71 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.935100</td>\n",
       "      <td>0.172875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.074566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.067739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.060267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.042803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.033441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.051764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.044976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('------ model is traing now -----')\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T08:59:20.417186Z",
     "iopub.status.busy": "2025-06-01T08:59:20.416699Z",
     "iopub.status.idle": "2025-06-01T08:59:20.422613Z",
     "shell.execute_reply": "2025-06-01T08:59:20.421947Z",
     "shell.execute_reply.started": "2025-06-01T08:59:20.417162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/reranker-Halong/checkpoint-1750/trainer_state.json\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to the folder\n",
    "path = '/kaggle/working/reranker-Halong'\n",
    "\n",
    "# Get all directories starting with 'checkpoint'\n",
    "checkpoint_dirs = glob.glob(os.path.join(path, 'checkpoint*'))\n",
    "\n",
    "if checkpoint_dirs != []:\n",
    "    trainer_state_dir = os.path.join(checkpoint_dirs[0], 'trainer_state.json')\n",
    "    print(trainer_state_dir)\n",
    "    \n",
    "else:\n",
    "    print('checkpoint_dirs is empty:', checkpoint_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T08:59:25.402091Z",
     "iopub.status.busy": "2025-06-01T08:59:25.401424Z",
     "iopub.status.idle": "2025-06-01T08:59:25.409132Z",
     "shell.execute_reply": "2025-06-01T08:59:25.408438Z",
     "shell.execute_reply.started": "2025-06-01T08:59:25.402066Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best checkpoint: reranker-Halong/checkpoint-1750\n",
      "\n",
      "{'best_global_step': 1750,\n",
      " 'best_metric': 0.033440593630075455,\n",
      " 'best_model_checkpoint': 'reranker-Halong/checkpoint-1750',\n",
      " 'epoch': 1.7948717948717947,\n",
      " 'eval_steps': 250,\n",
      " 'global_step': 1750,\n",
      " 'is_hyper_param_search': False,\n",
      " 'is_local_process_zero': True,\n",
      " 'is_world_process_zero': True,\n",
      " 'log_history': [{'epoch': 0.2564102564102564,\n",
      "                  'grad_norm': 7.725590705871582,\n",
      "                  'learning_rate': 8.395904436860068e-06,\n",
      "                  'loss': 0.9351,\n",
      "                  'step': 250},\n",
      "                 {'epoch': 0.2564102564102564,\n",
      "                  'eval_loss': 0.17287543416023254,\n",
      "                  'eval_runtime': 42.4157,\n",
      "                  'eval_samples_per_second': 22.963,\n",
      "                  'eval_steps_per_second': 2.876,\n",
      "                  'step': 250},\n",
      "                 {'epoch': 0.5128205128205128,\n",
      "                  'grad_norm': 19.961320877075195,\n",
      "                  'learning_rate': 9.232522796352584e-06,\n",
      "                  'loss': 0.1219,\n",
      "                  'step': 500},\n",
      "                 {'epoch': 0.5128205128205128,\n",
      "                  'eval_loss': 0.07456599175930023,\n",
      "                  'eval_runtime': 42.2635,\n",
      "                  'eval_samples_per_second': 23.046,\n",
      "                  'eval_steps_per_second': 2.887,\n",
      "                  'step': 500},\n",
      "                 {'epoch': 0.7692307692307693,\n",
      "                  'grad_norm': 3.3267483711242676,\n",
      "                  'learning_rate': 8.282674772036476e-06,\n",
      "                  'loss': 0.0909,\n",
      "                  'step': 750},\n",
      "                 {'epoch': 0.7692307692307693,\n",
      "                  'eval_loss': 0.0677388533949852,\n",
      "                  'eval_runtime': 42.3781,\n",
      "                  'eval_samples_per_second': 22.984,\n",
      "                  'eval_steps_per_second': 2.879,\n",
      "                  'step': 750},\n",
      "                 {'epoch': 1.0256410256410255,\n",
      "                  'grad_norm': 14.861263275146484,\n",
      "                  'learning_rate': 7.332826747720365e-06,\n",
      "                  'loss': 0.0558,\n",
      "                  'step': 1000},\n",
      "                 {'epoch': 1.0256410256410255,\n",
      "                  'eval_loss': 0.060266993939876556,\n",
      "                  'eval_runtime': 42.491,\n",
      "                  'eval_samples_per_second': 22.922,\n",
      "                  'eval_steps_per_second': 2.871,\n",
      "                  'step': 1000},\n",
      "                 {'epoch': 1.282051282051282,\n",
      "                  'grad_norm': 1.6475750207901,\n",
      "                  'learning_rate': 6.382978723404256e-06,\n",
      "                  'loss': 0.0452,\n",
      "                  'step': 1250},\n",
      "                 {'epoch': 1.282051282051282,\n",
      "                  'eval_loss': 0.04280288517475128,\n",
      "                  'eval_runtime': 42.4945,\n",
      "                  'eval_samples_per_second': 22.921,\n",
      "                  'eval_steps_per_second': 2.871,\n",
      "                  'step': 1250},\n",
      "                 {'epoch': 1.5384615384615383,\n",
      "                  'grad_norm': 16.790279388427734,\n",
      "                  'learning_rate': 5.433130699088146e-06,\n",
      "                  'loss': 0.0364,\n",
      "                  'step': 1500},\n",
      "                 {'epoch': 1.5384615384615383,\n",
      "                  'eval_loss': 0.04318014532327652,\n",
      "                  'eval_runtime': 42.4903,\n",
      "                  'eval_samples_per_second': 22.923,\n",
      "                  'eval_steps_per_second': 2.871,\n",
      "                  'step': 1500},\n",
      "                 {'epoch': 1.7948717948717947,\n",
      "                  'grad_norm': 0.0455363504588604,\n",
      "                  'learning_rate': 4.483282674772037e-06,\n",
      "                  'loss': 0.0468,\n",
      "                  'step': 1750},\n",
      "                 {'epoch': 1.7948717948717947,\n",
      "                  'eval_loss': 0.033440593630075455,\n",
      "                  'eval_runtime': 42.544,\n",
      "                  'eval_samples_per_second': 22.894,\n",
      "                  'eval_steps_per_second': 2.868,\n",
      "                  'step': 1750}],\n",
      " 'logging_steps': 250,\n",
      " 'max_steps': 2925,\n",
      " 'num_input_tokens_seen': 0,\n",
      " 'num_train_epochs': 3,\n",
      " 'save_steps': 250,\n",
      " 'stateful_callbacks': {'EarlyStoppingCallback': {'args': {'early_stopping_patience': 2,\n",
      "                                                           'early_stopping_threshold': 0.0},\n",
      "                                                  'attributes': {'early_stopping_patience_counter': 0}},\n",
      "                        'TrainerControl': {'args': {'should_epoch_stop': False,\n",
      "                                                    'should_evaluate': False,\n",
      "                                                    'should_log': False,\n",
      "                                                    'should_save': True,\n",
      "                                                    'should_training_stop': False},\n",
      "                                           'attributes': {}}},\n",
      " 'total_flos': 0.0,\n",
      " 'train_batch_size': 8,\n",
      " 'trial_name': None,\n",
      " 'trial_params': None}\n"
     ]
    }
   ],
   "source": [
    "if checkpoint_dirs != []:\n",
    "    import json\n",
    "    import pprint\n",
    "\n",
    "    with open(trainer_state_dir, \"r\") as f:\n",
    "        trainer_state = json.load(f)\n",
    "        \n",
    "    print('best checkpoint:', trainer.state.best_model_checkpoint, end='\\n\\n')\n",
    "    pprint.pprint(dict(trainer_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T08:59:31.659432Z",
     "iopub.status.busy": "2025-06-01T08:59:31.658721Z",
     "iopub.status.idle": "2025-06-01T08:59:33.133985Z",
     "shell.execute_reply": "2025-06-01T08:59:33.133257Z",
     "shell.execute_reply.started": "2025-06-01T08:59:31.659407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_best = CrossEncoder(trainer.state.best_model_checkpoint, num_labels=1, max_length=512, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T08:59:37.259297Z",
     "iopub.status.busy": "2025-06-01T08:59:37.258550Z",
     "iopub.status.idle": "2025-06-01T09:00:09.301513Z",
     "shell.execute_reply": "2025-06-01T09:00:09.300888Z",
     "shell.execute_reply.started": "2025-06-01T08:59:37.259270Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid_map': 0.9969199178644764, 'valid_mrr@10': 0.9969199178644764, 'valid_ndcg@10': 0.9977264666544443}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "valid_evaluator = get_evaluator(valid_hard, \"valid\")\n",
    "results = valid_evaluator(model_best)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T09:00:09.302828Z",
     "iopub.status.busy": "2025-06-01T09:00:09.302534Z",
     "iopub.status.idle": "2025-06-01T09:00:41.735817Z",
     "shell.execute_reply": "2025-06-01T09:00:41.735117Z",
     "shell.execute_reply.started": "2025-06-01T09:00:09.302809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_map': 0.9969262295081968, 'test_mrr@10': 0.9969262295081968, 'test_ndcg@10': 0.9977311255342508}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "test_evaluator = get_evaluator(test_hard, \"test\")\n",
    "results = test_evaluator(model_best)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T09:01:21.476606Z",
     "iopub.status.busy": "2025-06-01T09:01:21.476331Z",
     "iopub.status.idle": "2025-06-01T09:01:55.064867Z",
     "shell.execute_reply": "2025-06-01T09:01:55.064258Z",
     "shell.execute_reply.started": "2025-06-01T09:01:21.476586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fb250fdc364d629d87d06768b71c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b163b9744c40048e0bbb883e47b580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a7cb735a3a4b63b34710b9b964d902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/KhoaUIT/KhoaUIT-CrossEncoder-UIT-R2GQA/commit/61bf54460d640cc5efd24e0aaa2fba014711d1cc'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best.push_to_hub('KhoaUIT/Halong-CrossEncoder-UIT-R2GQA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7465448,
     "sourceId": 11878921,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
